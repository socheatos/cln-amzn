{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source https://nijianmo.github.io/amazon/index.html\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import functions as F\n",
    "import utils\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Simplifier\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# gets rid of the COLUMN ALREADY EXISTS error\n",
    "spark.conf.set('spark.sql.caseSensitive', True) \n",
    "spark.catalog.clearCache()\n",
    "\n",
    "\n",
    "REVIEW_DATA = '../dataset/Clothing_Shoes_and_Jewelry.json'\n",
    "PRODUCT_DATA = '../dataset/meta_Clothing_Shoes_and_Jewelry.json'\n",
    "SAMPLE_PRODUCTDATA = '../dataset/sample2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = spark.read.json(PRODUCT_DATA)\n",
    "product_data = product_data.drop('imageURL','imageURLHighRes','date','tech1','tech2','details','fit')\n",
    "# product_data = product_data.drop('similar_item')\n",
    "\n",
    "product_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {product_data.count()} entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex extract for rank of in clothing shoes & jewelry and cast to integer\n",
    "# main cateogries controls the rank\n",
    "EXP = r'(\\d*\\,*\\d*\\,*\\d+)\\s*in\\s*Clothing,\\s*Shoes\\s*\\&*\\s*Jewelry'\n",
    "product_data = product_data.withColumn('rank',F.regexp_replace(\n",
    "                                               F.regexp_extract('rank',EXP,1),\",\",'')\n",
    "                                                .cast('int')\n",
    "                                        )\n",
    "\n",
    "# regex extract price and change to float type\n",
    "EXP = r'\\$*(\\d+\\.*\\d+)'\n",
    "product_data = product_data.withColumn('price',F.regexp_extract('price',EXP,1)\n",
    "                                                .cast('float')\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up some null values\n",
    "# clean up main_cat if there is no value, then its main cat is Clothing_shoes_and_jewelry\n",
    "# we're gonna erly heavily on feature and description, drop null\n",
    "product_data = product_data.na.drop(subset=['description','feature'])\n",
    "# print(f'DF has {product_data.count()} entries')\n",
    "\n",
    "\n",
    "# change description, and feature into string type \n",
    "# product_data = product_data.select([F.concat_ws(',',c).alias(c) for c in  ['description','feature']])\n",
    "product_data = product_data.withColumn('description',F.concat_ws(',','description'))\n",
    "product_data = product_data.withColumn('feature',F.concat_ws(',','feature'))\n",
    "product_data = product_data.withColumn('category',F.concat_ws(',','category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all white space and digits\n",
    "EXP = r'Clothing, Shoes & Jewelry|\\W+|\\d+'\n",
    "\n",
    "product_data=product_data.withColumn('category_1', \n",
    "                                    F.lower(\n",
    "                                        F.regexp_replace('category',EXP,' ') \n",
    "                                        )\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the categories abit \n",
    "# product_data.select('category').distinct().show(20,truncate=0)\n",
    "\n",
    "# within each element remove white space?\n",
    "# remove numerical numbers \n",
    "# nlp to identify relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go straight into nlp\n",
    "# Wrapper for the processes \n",
    "#   https://www.johnsnowlabs.com/unleashing-the-power-of-text-tokenization-with-spark-nlp/ \n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "tokenizer = RegexTokenizer(inputCol=\"category_1\", outputCol=\"words\", pattern=\"\\\\W+\")\n",
    "df = tokenizer.transform(product_data.select('category_1'))\n",
    "# df_tokenized.select(\"category_1\", \"words\").show(truncate=False)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "df = remover.transform(df)\n",
    "# df_filtered.select(\"words\", \"filtered\").show(truncate=False)\n",
    "\n",
    "# use TF-IDF + maybe knn + NER to figure out what's important\n",
    "# TF-IDF\n",
    "    # cant use hasing TF bc i wont be able to extract the hash key value pairs \n",
    "        # hashing_tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "        # df_hashing = hashing_tf.transform(df)\n",
    "vectorizer = CountVectorizer(inputCol='filtered', outputCol='rawFeatures')\n",
    "model = vectorizer.fit(df)\n",
    "df_vect = model.transform(df)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "model = idf.fit(df_vect)\n",
    "tfidf_data = model.transform(df_vect)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data.select('words','features').show(truncate=False)\n",
    "# df_vect.select('words','rawFeatures').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data.select('features','words').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data.select(\"category_1\", \"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('filtered','rawFeatures').show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up any white space character and numbers \n",
    "# delete repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 5 column not truncated\n",
    "product_data.show(10, False)\n",
    "\n",
    "\n",
    "# need to change `description` into element string instead of array\n",
    "# drop nulls\n",
    "# drop images\n",
    "# change `price` to integer\n",
    "# modify rank \n",
    "# change `category`, `description`, `features` from array to string type\n",
    "    # note that features can be parsed throught bc it does contain key, value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where\n",
    "\n",
    "- asin - ID of the product, e.g. 0000031852\n",
    "- title - name of the product\n",
    "- feature - bullet-point format features of the product\n",
    "- description - description of the product\n",
    "- price - price in US dollars (at time of crawl)\n",
    "- imageURL - url of the product image\n",
    "- imageURL - url of the high resolution product image\n",
    "- related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "- salesRank - sales rank information\n",
    "- brand - brand name\n",
    "- categories - list of categories the product belongs to\n",
    "- tech1 - the first technical detail table of the product\n",
    "- tech2 - the second technical detail table of the product\n",
    "- similar - similar product table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end session \n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
